#!/usr/bin/python
"""
Perform core GFs completeness analysis, for given results of protein similarity search and core GFs file.
"""

# Usage: ./core_gf_analysis.py <core_gfs.tsv> <rapsearch_results.m8> -t 10 -o <completeness_analysis_output.tsv>


# Import modules
import argparse
import sys
import os
import time
import pandas as pd
import math


TIMESTAMP = time.strftime('%Y_%m_%d_%H%M%S')  # Get timestamp (for default output directory name)


### Command-line arguments
cmd_parser = argparse.ArgumentParser(
    description='Compute the core GF completeness score for user-specified set of core gene families and protein similarity search results. ',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)
# Positional arguments
cmd_parser.add_argument('core_gfs_file',
                        help='Core gene families file, as generated by the `get_core_gfs.py` script. ')
cmd_parser.add_argument('blast_output',
                        help='Tabulated output of your favorite protein similarity search tool (e.g. BLAST, RapSearch, DIAMOND, ...). ')
# Optional arguments
cmd_parser.add_argument('-o', '--output_dir', dest='output_dir', type=str,
                        help='Path of an output directory for the core GF analysis results. Will be created if it does not exist. ', default='core_gf_analysis_%s'%TIMESTAMP)
cmd_parser.add_argument('-t', '--top_hits', dest='top_hits', type=int,
                        help='Top protein similarity search hits to consider when looking for a GF. ', default=10)
cmd_parser.add_argument('--raw', dest='raw_evalues',
                        help='This flag must be provided if the e-values of the protein similarity search are not already converted to log10 (i.e. \'raw\' e-values). ',
                        action='store_true', default=False)


### Functions
def read_all_gfs(core_gfs_file):
    """Read a core GF tabulated file, return a dictionary of GFs. """
    sys.stderr.write(
        '[' + time.strftime("%H:%M:%S") + '] Reading all GFs from core GFs file (' + core_gfs_file + '). \n')
    all_gfs_dict = {}
    with open(core_gfs_file, 'r') as in_file:
        next(in_file)  # Skip header line
        for line in in_file:
            fields = line.strip().split('\t')
            all_gfs_dict[fields[0]] = {
                'members': fields[-1].split('|'),
                'n_species': fields[2],
                'weight': fields[3],
                'not_chosen': False,
                'is_core_gf': fields[4] in 'True',
                'represented': False,
                'query_list': []
            }
    sys.stderr.write(
        '[' + time.strftime("%H:%M:%S") + '] ' + str(len(all_gfs_dict.keys())) + ' gene families and ' + str(len(
            [gf for gf in all_gfs_dict if all_gfs_dict[gf]['is_core_gf'] == True])) + ' core gene families found. \n')
    return all_gfs_dict


def get_gene_gf_map(all_gfs_dict):
    """Map each gene identifier to a GF. Return a gene_id-gf dict, used to perform lookup after. """
    gene_gf_map = {}
    for gf in all_gfs_dict:
        for gene in all_gfs_dict[gf]['members']:
            gene_gf_map[gene] = gf
    # Return gene_gf_map
    sys.stderr.write('[' + time.strftime("%H:%M:%S") + '] ' + str(len(gene_gf_map)) + ' elements in Gene-GF map. \n')
    return gene_gf_map


def gf_lookup(gene_id, gene_gf_map):
    """Look if a gene belongs to any gene family. Returns the name of the family, None if no family was found.
    Such method can be used because each gene belongs to only one family. """
    if gene_id in gene_gf_map:
        return gene_gf_map[gene_id]
    else:
        return None


def read_blast_output(blast_output, raw_evalues=False):
    """Read a similarity search output file (`.m8` file), keeping only query, subject and e-value columns.
    Return it as sorted and indexed dataframe."""
    sys.stderr.write('[' + time.strftime("%H:%M:%S") + '] Reading similarity search output file (%s)\n' % blast_output)
    # Read the BLAST output and only keep the columns we're interested in. Then rename columns + set index (fast lookup)
    blast_df = pd.read_csv(blast_output, sep='\t', header=None, comment='#', usecols=[0, 1, 10])
    blast_df = blast_df.rename(columns={0: "query_gene", 1: "subject", 10: "log_e_value"})
    # Convert e-values to log10 if  --raw flag is provided (RapSearch2 takes care of that!)
    if raw_evalues:
        sys.stderr.write('[' + time.strftime("%H:%M:%S") + '] Converting e-values to log10 (\'--raw\' flag was provided).\n')
        blast_df['log_e_value'] = [math.log10(e_val) if e_val > sys.float_info.min else math.log10(sys.float_info.min)
                                   for e_val in blast_df['log_e_value'].tolist()]
        # print min(blast_df['log_e_value'])  # Debug
    # Sort and index
    blast_df = blast_df.sort_values(by=['query_gene', 'log_e_value'], ascending=[True, True])
    blast_df = blast_df.set_index(['query_gene'])
    return blast_df


# Note: In TRAPID, the homology assignments work with top 1 for clade/species DB, top 5 for GF representatives.
def process_blast_output(blast_df, n_hits, gene_gf_map, all_gfs_dict):
    """Process the whole BLAST/RapSearch2 output.
    Will modify the dictionary passed as parameter to set to `True` families that are represented.
    For a query, we take the top `n_hits` from the results and check for GF members to assign a GF to each top hit. The
    best scoring GF is then considered represented. """
    # Get list of all queries
    all_queries = list(blast_df.index.unique())
    sys.stderr.write(
        '[' + time.strftime("%H:%M:%S") + '] ' + str(len(all_queries)) + ' queries in similarity search output\n')
    for query in all_queries:
        scored_gfs = {}  # Dict to store found GFs and associated score
        top_hits = blast_df.loc[query][0:n_hits]
        if not isinstance(top_hits, pd.DataFrame):
            # sys.stderr.write("Not a dataframe.\n")  # Debug
            top_hits = blast_df.loc[[query]][0:n_hits]
        # print top_hits.columns
        gfs = [gf_lookup(gene_id=subject, gene_gf_map=gene_gf_map) for subject in top_hits['subject']]
        top_hit_gf = gfs[0]
        log_e_values = top_hits['log_e_value'].tolist()
        for gf, log_e_value in zip(gfs, log_e_values):
            if gf not in scored_gfs:
                scored_gfs[gf] = abs(log_e_value)
            else:
                scored_gfs[gf] += abs(log_e_value)
        # TODO: CLEAN THIS MESS OTHERWISE IT IS UNREADABLE
        # Remove 'None' BEFORE taking the 'max' (otherwise we underestimate the completeness...)
        if None in scored_gfs.keys():
            print "-----"  # This should never happen!
            del scored_gfs[None]
        # Weighting scores with GF weight.
        # print scored_gfs
        for gf in scored_gfs:
            scored_gfs[gf] = scored_gfs[gf] * float(all_gfs_dict[gf]['weight'])
        if scored_gfs:
            best_gf = max(scored_gfs, key=scored_gfs.get)
            all_gfs_dict[best_gf]['represented'] = True
            all_gfs_dict[best_gf]['query_list'].append(query)
            if best_gf != top_hit_gf and top_hit_gf is not None:
                sys.stderr.write('[' + time.strftime(
                    "%H:%M:%S") + '] Warning: the GF of the top result for query ' + query + ' (' + str(
                    top_hit_gf) + '|is_core_gf=' + str(all_gfs_dict[top_hit_gf]['is_core_gf']) + ', score=' + str(
                    scored_gfs[top_hit_gf]) + ') was not the one assigned (' + str(best_gf) + '|is_core_gf=' + str(
                    all_gfs_dict[best_gf]['is_core_gf']) + ', score=' + str(scored_gfs[best_gf]) + ').\n')
                # sys.stderr.write(str(scored_gfs)+'\n')
                all_gfs_dict[top_hit_gf]['not_chosen'] = True
    # sys.stderr.write("In "+str(count_none)+" queries, ...\n")


def get_completeness_score(all_gfs_dict):
    """Compute the core GF completeness score. """
    total_weight = sum([float(all_gfs_dict[a]["weight"]) for a in all_gfs_dict.keys() if all_gfs_dict[a]['is_core_gf']])
    current_weight = sum([float(all_gfs_dict[a]["weight"]) for a in all_gfs_dict.keys() if
                          all_gfs_dict[a]["represented"] and all_gfs_dict[a]['is_core_gf']])
    sys.stderr.write('[' + time.strftime("%H:%M:%S") + '] Calculating weighted core GF score. \n')
    # print current_weight
    # print total_weight
    return current_weight / total_weight


def completeness_report(all_gfs_dict, output_dir, file_name):
    """Generate a core GF completeness report. Output to `file_name` in `output_dir`. """
    sys.stderr.write('[' + time.strftime("%H:%M:%S") + '] Generating core GF completeness report. \n')
    represented_gfs = [gf for gf in all_gfs_dict if all_gfs_dict[gf]['represented'] and all_gfs_dict[gf]['is_core_gf']]
    missing_gfs = [gf for gf in all_gfs_dict if not all_gfs_dict[gf]['represented'] and all_gfs_dict[gf]['is_core_gf']]
    core_gfs = [gf for gf in all_gfs_dict if all_gfs_dict[gf]['is_core_gf']]
    # core_gfs_dict["HOM004486"]['not_chosen']=True  # Debug
    not_chosen_gfs = [gf for gf in all_gfs_dict if all_gfs_dict[gf]['not_chosen']]
    not_chosen_missing_gfs = [gf for gf in all_gfs_dict if
                              not all_gfs_dict[gf]['represented'] and all_gfs_dict[gf]['not_chosen'] and
                              all_gfs_dict[gf]['is_core_gf']]
    completeness_score = get_completeness_score(all_gfs_dict=all_gfs_dict)
    # sys.exit()
    with open(os.path.join(output_dir, file_name), 'wb') as out_file:
        out_file.write('# Core GF completeness score:\t' + "{:.5f}".format(completeness_score) + '\n')
        out_file.write(
            '# Represented core gene families:\t' + str(len(represented_gfs)) + '/' + str(len(core_gfs)) + '\n')
        out_file.write('# Missing core gene families:\t' + str(len(missing_gfs)) + '/' + str(len(core_gfs)) + '\n')
        out_file.write('# In ' + str(len(
            not_chosen_gfs)) + ' cases, the core gene family associated with the top hit was not the one chosen as \'best\' gene family. \n')
        out_file.write('# ' + str(len(not_chosen_missing_gfs)) + ' of these ' + str(
            len(not_chosen_gfs)) + ' were core gene families, now considered as missing. ' + ', '.join(
            not_chosen_missing_gfs) + '\n')
        out_file.write('\n')
        # out_file.write('missing_gf\tn_genes\n')
        out_file.write('missing_gf\tn_genes\tn_species\tgf_weight\n')
        for gf in missing_gfs:
            out_file.write('\t'.join([gf, str(len(all_gfs_dict[gf]['members'])), str(all_gfs_dict[gf]['n_species']),
                                      str(all_gfs_dict[gf]['weight'])]) + '\n')


def represented_core_gf_report(all_gfs_dict, output_dir, file_name):
    """Generate a tabulated file reporting represented core GFs and the list of corresponding similarity search queries. """
    sys.stderr.write('[' + time.strftime("%H:%M:%S") + '] Generating represented core GF report. \n')
    represented_gfs = [gf for gf in all_gfs_dict if all_gfs_dict[gf]['represented'] and all_gfs_dict[gf]['is_core_gf']]
    with open(os.path.join(output_dir, file_name), 'wb') as out_file:
        out_file.write('represented_gf\tn_genes\tn_species\tgf_weight\tquery_list\n')
        for gf in represented_gfs:
            out_file.write('\t'.join([gf, str(len(all_gfs_dict[gf]['members'])), str(all_gfs_dict[gf]['n_species']),
                                      str(all_gfs_dict[gf]['weight']), ','.join(all_gfs_dict[gf]['query_list'])]) + '\n')


def main(core_gfs_file, blast_output, output_dir, top_hits, raw_evalues):
    """Script execution. """
    if not os.path.exists(output_dir):
        sys.stderr.write('[' + time.strftime("%H:%M:%S") + '] Creating output directory \'%s\'. \n' % output_dir)
        os.makedirs(output_dir)
    else:
        sys.stderr.write('[' + time.strftime("%H:%M:%S") + '] Output directory \'%s\' already exists. \n' % output_dir)
    all_gfs = read_all_gfs(core_gfs_file=core_gfs_file)
    gene_gf_map = get_gene_gf_map(all_gfs_dict=all_gfs)
    blast_df = read_blast_output(blast_output=blast_output, raw_evalues=raw_evalues)
    process_blast_output(blast_df=blast_df, n_hits=top_hits, gene_gf_map=gene_gf_map,
                         all_gfs_dict=all_gfs)
    completeness_report(all_gfs_dict=all_gfs, output_dir=output_dir, file_name="core_gf_completeness_report.tsv")
    represented_core_gf_report(all_gfs_dict=all_gfs, output_dir=output_dir, file_name="represented_core_gf_report.tsv")
    sys.stderr.write('[' + time.strftime("%H:%M:%S") + '] Core GF completeness analysis finished!\n')
    # Testing completeness score calculation
    # completeness_score=get_completeness_score(core_gfs_dict=core_gfs)
    # sys.stderr.write(str(completeness_score)+'\n')


### Script execution when called from the command-line
if __name__ == '__main__':
    # Parse command-line arguments
    cmd_args = cmd_parser.parse_args()
    # sys.stderr.write(str(cmd_args)+'\n')  # Debug
    main(core_gfs_file=cmd_args.core_gfs_file, blast_output=cmd_args.blast_output, output_dir=cmd_args.output_dir,
         top_hits=cmd_args.top_hits, raw_evalues=cmd_args.raw_evalues)
